{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHUBoyoC4RolZHkrKF+92u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkSharma9604/AKsharma/blob/main/TextClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Data for the models\n",
        "data = {\n",
        "    'Model': ['BERT', 'RoBERTa', 'GPT', 'DistilBERT', 'ALBERT'],\n",
        "    'Accuracy': [0.92, 0.93, 0.88, 0.91, 0.90],\n",
        "    'F1-Score': [0.91, 0.92, 0.85, 0.89, 0.88],\n",
        "    'Inference Time (ms)': [120, 130, 150, 90, 110],\n",
        "    'Memory Usage (MB)': [400, 450, 600, 250, 300],\n",
        "    'Model Size (MB)': [450, 470, 1200, 200, 250]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Criteria for minimization (Inference Time, Memory Usage, and Model Size)\n",
        "criteria_min = ['Inference Time (ms)', 'Memory Usage (MB)', 'Model Size (MB)']\n",
        "\n",
        "# Normalize the data\n",
        "def normalize(df, criteria_min):\n",
        "    normalized_df = df.copy()\n",
        "\n",
        "    for column in df.columns[1:]:\n",
        "        if column in criteria_min:\n",
        "            # For minimization\n",
        "            min_val = df[column].min()\n",
        "            max_val = df[column].max()\n",
        "            normalized_df[column] = (max_val - df[column]) / (max_val - min_val)\n",
        "        else:\n",
        "            # For maximization\n",
        "            min_val = df[column].min()\n",
        "            max_val = df[column].max()\n",
        "            normalized_df[column] = (df[column] - min_val) / (max_val - min_val)\n",
        "\n",
        "    return normalized_df\n",
        "\n",
        "# Normalize the data\n",
        "normalized_df = normalize(df, criteria_min)\n",
        "\n",
        "# Weights for each criterion\n",
        "weights = {\n",
        "    'Accuracy': 0.4,\n",
        "    'F1-Score': 0.3,\n",
        "    'Inference Time (ms)': 0.2,\n",
        "    'Memory Usage (MB)': 0.1,\n",
        "    'Model Size (MB)': 0.1\n",
        "}\n",
        "\n",
        "# Calculate the weighted normalized decision matrix\n",
        "weighted_normalized_df = normalized_df.copy()\n",
        "\n",
        "for column in weighted_normalized_df.columns[1:]:\n",
        "    weighted_normalized_df[column] = weighted_normalized_df[column] * weights[column]\n",
        "\n",
        "# Calculate the ideal and negative-ideal solutions\n",
        "ideal_solution = weighted_normalized_df.iloc[:, 1:].max()\n",
        "negative_ideal_solution = weighted_normalized_df.iloc[:, 1:].min()\n",
        "\n",
        "# Calculate the Euclidean distance from the ideal and negative-ideal solutions\n",
        "def euclidean_distance(df, solution):\n",
        "    return np.sqrt(((df - solution) ** 2).sum(axis=1))\n",
        "\n",
        "distance_to_ideal = euclidean_distance(weighted_normalized_df.iloc[:, 1:], ideal_solution)\n",
        "distance_to_negative_ideal = euclidean_distance(weighted_normalized_df.iloc[:, 1:], negative_ideal_solution)\n",
        "\n",
        "# Calculate the relative closeness to the ideal solution\n",
        "relative_closeness = distance_to_negative_ideal / (distance_to_ideal + distance_to_negative_ideal)\n",
        "\n",
        "# Add the relative closeness to the dataframe\n",
        "df['Relative Closeness'] = relative_closeness\n",
        "\n",
        "# Sort the models by relative closeness (higher is better)\n",
        "sorted_df = df.sort_values(by='Relative Closeness', ascending=False)\n",
        "\n",
        "# Display the sorted results\n",
        "print(\"Sorted Models based on TOPSIS Method:\")\n",
        "print(sorted_df[['Model', 'Relative Closeness']])\n"
      ],
      "metadata": {
        "id": "9jMrwrSPpOsH",
        "outputId": "fa21861b-3c20-4830-bd88-311eec4eaa9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted Models based on TOPSIS Method:\n",
            "        Model  Relative Closeness\n",
            "1     RoBERTa            0.776105\n",
            "0        BERT            0.750565\n",
            "3  DistilBERT            0.651307\n",
            "4      ALBERT            0.477056\n",
            "2         GPT            0.000000\n"
          ]
        }
      ]
    }
  ]
}